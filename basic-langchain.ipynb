{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Why did the scarecrow win an award?\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Because he was outstanding in his field!\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Why did the scarecrow win an award?\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Because he was outstanding in his field!\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m29\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Why did the computer go to the doctor? \\nBecause it had a virus!\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  \u001b[32m\"Why couldn't the bicycle find its way home? \\nIt lost its bearings!\"\u001b[39m,\n",
       "  \u001b[32m\"Hello! I am an AI digital assistant designed to provide information and assistance on a variety of topics. How can I help you today?\"\u001b[39m\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.batch([\n",
    "    [ new HumanMessage(\"Tell me a joke\") ],\n",
    "    [ new HumanMessage(\"Hi, Who are you?\") ],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " scientists\n",
      " trust\n",
      " atoms\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " make\n",
      " up\n",
      " everything\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const stream = await simpleChain.stream([\n",
    "     new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"replace\",\n",
      "      path: \"\",\n",
      "      value: {\n",
      "        id: \"bde7749f-afba-439a-a03b-e8f24a56515c\",\n",
      "        name: \"RunnableSequence\",\n",
      "        type: \"chain\",\n",
      "        streamed_output: [],\n",
      "        final_output: undefined,\n",
      "        logs: {}\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI\",\n",
      "      value: {\n",
      "        id: \"5fb53e79-e07b-430d-acbf-c02dc90a99a3\",\n",
      "        name: \"ChatOpenAI\",\n",
      "        type: \"llm\",\n",
      "        tags: [ \"seq:step:1\" ],\n",
      "        metadata: {},\n",
      "        start_time: \"2025-02-14T11:32:26.750Z\",\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: undefined,\n",
      "        end_time: undefined\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser\",\n",
      "      value: {\n",
      "        id: \"b158219a-740f-4f04-82fb-7b6cc484570b\",\n",
      "        name: \"StrOutputParser\",\n",
      "        type: \"parser\",\n",
      "        tags: [ \"seq:step:2\" ],\n",
      "        metadata: {},\n",
      "        start_time: \"2025-02-14T11:32:27.339Z\",\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: undefined,\n",
      "        end_time: undefined\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"Why\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"Why\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"Why\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"Why\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"Why\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" did\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" did\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" did\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" did\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" did\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" the\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" the\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" the\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" the\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" the\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" scare\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" scare\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" scare\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" scare\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" scare\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"crow\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"crow\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"crow\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"crow\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"crow\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" win\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" win\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" win\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" win\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" win\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" an\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" an\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" an\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" an\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" an\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" award\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" award\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" award\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" award\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" award\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"?\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"?\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"?\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"?\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"?\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" Because\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" Because\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" Because\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" Because\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" Because\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" he\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" he\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" he\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" he\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" he\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" was\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" was\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" was\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" was\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" was\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" outstanding\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" outstanding\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" outstanding\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" outstanding\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" outstanding\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" in\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" in\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" in\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" in\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" in\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" his\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" his\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" his\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" his\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" his\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" field\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" field\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" field\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" field\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" field\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"!\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"!\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"!\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"!\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"!\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: \"stop\" },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/final_output\",\n",
      "      value: { generations: [ [Array] ] }\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/end_time\",\n",
      "      value: \"2025-02-14T11:32:27.525Z\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/final_output\",\n",
      "      value: {\n",
      "        output: \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/end_time\",\n",
      "      value: \"2025-02-14T11:32:27.526Z\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"replace\",\n",
      "      path: \"/final_output\",\n",
      "      value: {\n",
      "        output: \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const stream = await simpleChain.streamLog([\n",
    "     new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"你好！有什么可以帮助你的吗？\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"你好！有什么可以帮助你的吗？\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m9\u001b[39m, totalTokens: \u001b[33m27\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const fakeLLM = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://api.openai.com/v12\",\n",
    "    },\n",
    "    maxRetries: 0,\n",
    "});\n",
    "\n",
    "// await fakeLLM.invoke(\"你好\")\n",
    "\n",
    "const realLLM = new ChatOpenAI({\n",
    "  // configuration: {\n",
    "  //   baseURL: \"https://api.openai.com/v1\",\n",
    "  // }\n",
    "})\n",
    "const llmWithFallback = fakeLLM.withFallbacks({\n",
    "    fallbacks: [realLLM]\n",
    "})\n",
    "\n",
    "await llmWithFallback.invoke(\"你好\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const greetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [],\n",
    "  template: \"hello world\",\n",
    "});\n",
    "const formattedGreetingPrompt = await greetingPrompt.format();\n",
    "\n",
    "console.log(formattedGreetingPrompt);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello，Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const personalizedGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"name\"],\n",
    "  template: \"hello，{name}\",\n",
    "});\n",
    "const formattedPersonalizedGreeting = await personalizedGreetingPrompt.format({\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "\n",
    "console.log(formattedPersonalizedGreeting);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good night, Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "const multiVariableGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"timeOfDay\", \"name\"],\n",
    "  template: \"good {timeOfDay}, {name}\",\n",
    "});\n",
    "const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\n",
    "  timeOfDay: \"night\",\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "\n",
    "console.log(formattedMultiVariableGreeting);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"timeOfDay\", \"name\" ]\n",
      "good morning, Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "const autoInferTemplate = PromptTemplate.fromTemplate(\"good {timeOfDay}, {name}\");\n",
    "console.log(autoInferTemplate.inputVariables);\n",
    "// ['timeOfDay', 'name']\n",
    "\n",
    "const formattedAutoInferTemplate = await autoInferTemplate.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "console.log(formattedAutoInferTemplate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
