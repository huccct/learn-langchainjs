{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Why did the scarecrow win an award?\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Because he was outstanding in his field!\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Why did the scarecrow win an award?\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Because he was outstanding in his field!\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m29\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Why did the computer go to the doctor? \\nBecause it had a virus!\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  \u001b[32m\"Why couldn't the bicycle find its way home? \\nIt lost its bearings!\"\u001b[39m,\n",
       "  \u001b[32m\"Hello! I am an AI digital assistant designed to provide information and assistance on a variety of topics. How can I help you today?\"\u001b[39m\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.batch([\n",
    "    [ new HumanMessage(\"Tell me a joke\") ],\n",
    "    [ new HumanMessage(\"Hi, Who are you?\") ],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " scientists\n",
      " trust\n",
      " atoms\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " make\n",
      " up\n",
      " everything\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const stream = await simpleChain.stream([\n",
    "     new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"replace\",\n",
      "      path: \"\",\n",
      "      value: {\n",
      "        id: \"bde7749f-afba-439a-a03b-e8f24a56515c\",\n",
      "        name: \"RunnableSequence\",\n",
      "        type: \"chain\",\n",
      "        streamed_output: [],\n",
      "        final_output: undefined,\n",
      "        logs: {}\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI\",\n",
      "      value: {\n",
      "        id: \"5fb53e79-e07b-430d-acbf-c02dc90a99a3\",\n",
      "        name: \"ChatOpenAI\",\n",
      "        type: \"llm\",\n",
      "        tags: [ \"seq:step:1\" ],\n",
      "        metadata: {},\n",
      "        start_time: \"2025-02-14T11:32:26.750Z\",\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: undefined,\n",
      "        end_time: undefined\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser\",\n",
      "      value: {\n",
      "        id: \"b158219a-740f-4f04-82fb-7b6cc484570b\",\n",
      "        name: \"StrOutputParser\",\n",
      "        type: \"parser\",\n",
      "        tags: [ \"seq:step:2\" ],\n",
      "        metadata: {},\n",
      "        start_time: \"2025-02-14T11:32:27.339Z\",\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: undefined,\n",
      "        end_time: undefined\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"Why\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"Why\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"Why\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"Why\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"Why\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" did\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" did\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" did\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" did\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" did\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" the\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" the\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" the\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" the\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" the\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" scare\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" scare\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" scare\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" scare\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" scare\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"crow\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"crow\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"crow\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"crow\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"crow\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" win\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" win\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" win\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" win\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" win\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" an\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" an\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" an\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" an\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" an\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" award\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" award\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" award\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" award\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" award\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"?\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"?\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"?\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"?\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"?\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" Because\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" Because\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" Because\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" Because\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" Because\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" he\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" he\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" he\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" he\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" he\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" was\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" was\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" was\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" was\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" was\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" outstanding\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" outstanding\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" outstanding\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" outstanding\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" outstanding\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" in\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" in\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" in\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" in\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" in\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" his\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" his\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" his\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" his\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" his\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \" field\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \" field\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \" field\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \" field\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \" field\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"!\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"!\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"!\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"!\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: null },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"!\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/streamed_output/-\",\n",
      "      value: \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \"add\", path: \"/streamed_output/-\", value: \"\" } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output_str/-\",\n",
      "      value: \"\"\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/streamed_output/-\",\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \"\",\n",
      "        generationInfo: { prompt: 0, completion: 0, finish_reason: \"stop\" },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: [Object]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/final_output\",\n",
      "      value: { generations: [ [Array] ] }\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/ChatOpenAI/end_time\",\n",
      "      value: \"2025-02-14T11:32:27.525Z\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/final_output\",\n",
      "      value: {\n",
      "        output: \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      op: \"add\",\n",
      "      path: \"/logs/StrOutputParser/end_time\",\n",
      "      value: \"2025-02-14T11:32:27.526Z\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \"replace\",\n",
      "      path: \"/final_output\",\n",
      "      value: {\n",
      "        output: \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const stream = await simpleChain.streamLog([\n",
    "     new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"你好！有什么可以帮助你的吗？\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"你好！有什么可以帮助你的吗？\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m9\u001b[39m, totalTokens: \u001b[33m27\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const fakeLLM = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://api.openai.com/v12\",\n",
    "    },\n",
    "    maxRetries: 0,\n",
    "});\n",
    "\n",
    "// await fakeLLM.invoke(\"你好\")\n",
    "\n",
    "const realLLM = new ChatOpenAI({\n",
    "  // configuration: {\n",
    "  //   baseURL: \"https://api.openai.com/v1\",\n",
    "  // }\n",
    "})\n",
    "const llmWithFallback = fakeLLM.withFallbacks({\n",
    "    fallbacks: [realLLM]\n",
    "})\n",
    "\n",
    "await llmWithFallback.invoke(\"你好\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const greetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [],\n",
    "  template: \"hello world\",\n",
    "});\n",
    "const formattedGreetingPrompt = await greetingPrompt.format();\n",
    "\n",
    "console.log(formattedGreetingPrompt);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello，Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const personalizedGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"name\"],\n",
    "  template: \"hello，{name}\",\n",
    "});\n",
    "const formattedPersonalizedGreeting = await personalizedGreetingPrompt.format({\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "\n",
    "console.log(formattedPersonalizedGreeting);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good night, Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "const multiVariableGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"timeOfDay\", \"name\"],\n",
    "  template: \"good {timeOfDay}, {name}\",\n",
    "});\n",
    "const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\n",
    "  timeOfDay: \"night\",\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "\n",
    "console.log(formattedMultiVariableGreeting);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"timeOfDay\", \"name\" ]\n",
      "good morning, Tunan\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "const autoInferTemplate = PromptTemplate.fromTemplate(\"good {timeOfDay}, {name}\");\n",
    "console.log(autoInferTemplate.inputVariables);\n",
    "// ['timeOfDay', 'name']\n",
    "\n",
    "const formattedAutoInferTemplate = await autoInferTemplate.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Tunan\",\n",
    "});\n",
    "console.log(formattedAutoInferTemplate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个工具，它是锤子。\n",
      "这是一个工具，它是改锥。\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const initialPrompt = new PromptTemplate({\n",
    "  template: \"这是一个{type}，它是{item}。\",\n",
    "  inputVariables: [\"type\", \"item\"],\n",
    "});\n",
    "\n",
    "\n",
    "const partialedPrompt = await initialPrompt.partial({\n",
    "  type: \"工具\",\n",
    "});\n",
    "\n",
    "const formattedPrompt = await partialedPrompt.format({\n",
    "  item: \"锤子\",\n",
    "});\n",
    "\n",
    "console.log(formattedPrompt);\n",
    "\n",
    "const formattedPrompt2 = await partialedPrompt.format({\n",
    "  item: \"改锥\",\n",
    "});\n",
    "\n",
    "console.log(formattedPrompt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天是2/14/2025，我们去爬山。\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const promptWithDate = new PromptTemplate({\n",
    "  template: \"今天是{date}，{activity}。\",\n",
    "  inputVariables: [\"date\", \"activity\"],\n",
    "});\n",
    "\n",
    "const partialedPromptWithDate = await promptWithDate.partial({\n",
    "  date: getCurrentDateStr,\n",
    "});\n",
    "\n",
    "const formattedPromptWithDate = await partialedPromptWithDate.format({\n",
    "  activity: \"我们去爬山\",\n",
    "});\n",
    "\n",
    "console.log(formattedPromptWithDate);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/14/2025 下午好!\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "function generateGreeting(timeOfDay) {\n",
    "  return () => {\n",
    "    const date = getCurrentDateStr()\n",
    "    switch (timeOfDay) {\n",
    "      case 'morning':\n",
    "        return date + ' 早上好';\n",
    "      case 'afternoon':\n",
    "        return date + ' 下午好';\n",
    "      case 'evening':\n",
    "        return date + ' 晚上好';\n",
    "      default:\n",
    "        return date + ' 你好';\n",
    "    }\n",
    "  };\n",
    "}\n",
    "\n",
    "const prompt = new PromptTemplate({\n",
    "  template: \"{greeting}!\",\n",
    "  inputVariables: [\"greeting\"],\n",
    "});\n",
    "\n",
    "const currentTimeOfDay = 'afternoon';\n",
    "const partialPrompt = await prompt.partial({\n",
    "  greeting: generateGreeting(currentTimeOfDay),\n",
    "});\n",
    "\n",
    "const formattedPrompt = await partialPrompt.format();\n",
    "\n",
    "console.log(formattedPrompt);\n",
    "// 输出: 3/21/2024 下午好!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  SystemMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"你是一个专\\n业的翻译员，你的任务是将文本从中文翻译成法语。\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"你是一个专\\n业的翻译员，你的任务是将文本从中文翻译成法语。\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"请翻译这句话：你好，世界\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"请翻译这句话：你好，世界\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const translateInstructionTemplate = SystemMessagePromptTemplate.fromTemplate(`你是一个专\n",
    "业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。`);\n",
    "\n",
    "const userQuestionTemplate = HumanMessagePromptTemplate.fromTemplate(\"请翻译这句话：{text}\")\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  translateInstructionTemplate,\n",
    "  userQuestionTemplate,\n",
    "]);\n",
    "\n",
    "const formattedChatPrompt = await chatPrompt.formatMessages({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"法语\",\n",
    "  text: \"你好，世界\",\n",
    "});\n",
    "\n",
    "console.log(formattedChatPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Bonjour, monde.\"\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import { load } from \"dotenv\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const systemTemplate = \"你是一个专业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。\";\n",
    "const humanTemplate = \"请翻译这句话：{text}\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemTemplate],\n",
    "  [\"human\", humanTemplate],\n",
    "]);\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const outputParser = new StringOutputParser();\n",
    "\n",
    "const chain = chatPrompt.pipe(model).pipe(outputParser);\n",
    "\n",
    "await chain.invoke({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"法语\",\n",
    "  text: \"你好，世界\",\n",
    "});\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一个智能管家，今天是 2/25/2025，现在是 晚上，你的主人的信息是姓名是 张三, 性别是 male, \n",
      "根据上下文，完成主人的需求\n",
      "\n",
      "我想吃 晚上 的 lemon。 \n",
      "再重复一遍我的信息 姓名是 张三, 性别是 male\n"
     ]
    }
   ],
   "source": [
    "import {\n",
    "  PromptTemplate,\n",
    "  PipelinePromptTemplate,\n",
    "} from \"@langchain/core/prompts\";\n",
    "\n",
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const fullPrompt = PromptTemplate.fromTemplate(`\n",
    "你是一个智能管家，今天是 {date}，你的主人的信息是{info}, \n",
    "根据上下文，完成主人的需求\n",
    "{task}`);\n",
    "\n",
    "const datePrompt = PromptTemplate.fromTemplate(\"{date}，现在是 {period}\")\n",
    "const periodPrompt = await datePrompt.partial({\n",
    "    date: getCurrentDateStr\n",
    "})\n",
    "\n",
    "const infoPrompt = PromptTemplate.fromTemplate(\"姓名是 {name}, 性别是 {gender}\");\n",
    "\n",
    "const taskPrompt = PromptTemplate.fromTemplate(`\n",
    "我想吃 {period} 的 {food}。 \n",
    "再重复一遍我的信息 {info}`);\n",
    "\n",
    "\n",
    "const composedPrompt = await new PipelinePromptTemplate({\n",
    "  pipelinePrompts: [\n",
    "    {\n",
    "      name: \"date\",\n",
    "      prompt: periodPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"info\",\n",
    "      prompt: infoPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"task\",\n",
    "      prompt: taskPrompt,\n",
    "    },\n",
    "  ],\n",
    "  finalPrompt: fullPrompt,\n",
    "})\n",
    "\n",
    "const formattedPrompt = await composedPrompt.format({\n",
    "  period: '晚上',\n",
    "  name: \"张三\",\n",
    "  gender: \"male\",\n",
    "  food: \"lemon\"\n",
    "})\n",
    "\n",
    "console.log(formattedPrompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
